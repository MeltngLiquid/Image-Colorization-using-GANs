# -*- coding: utf-8 -*-
"""fine-tune_generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S_x2gE3-5IwjEV7rPI32BV_9jgsvXclN
"""

from keras.callbacks import ModelCheckpoint
from keras.models import load_model
# Load the pretrained generator
checkpoint_filepath_generator = '/content/drive/MyDrive/models/model.keras'
g_model = load_model(checkpoint_filepath_generator)

# Define the discriminator and GAN models
d_model = define_discriminator(image_shape=(256, 256, 3))
gan_model = define_gan(g_model, d_model, image_shape=(256, 256, 1))

# Define GAN checkpoint path
checkpoint_filepath_gan = '/content/drive/MyDrive/models/weightst.keras'

# Load GAN weights if a checkpoint exists
if os.path.exists(checkpoint_filepath_gan):
    print("Loading GAN weights from checkpoint...")
    gan_model.load_weights(checkpoint_filepath_gan)

# Training function with checkpointing
def train_with_checkpoints(d_model, g_model, gan_model, dataset, n_epochs=20, n_batch=128):
    """
    Train GAN using a pretrained generator and save checkpoints during training.
    """
    n_patch = d_model.output_shape[1]
    bat_per_epo = int(4000 / n_batch)
    n_steps = bat_per_epo * n_epochs

    for i in range(n_steps):
        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)
        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)
        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)

        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)
        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])

        print(f'>Step {i+1}/{n_steps}, d1[{d_loss1:.3f}] d2[{d_loss2:.3f}] g[{g_loss:.3f}]')

        if (i + 1) % 5 == 0:
            gan_model.save_weights(checkpoint_filepath_gan)
            print(f"GAN checkpoint saved at step {i+1}.")

train_with_checkpoints(d_model, g_model, gan_model, train_dataset, n_epochs=20, n_batch=128)