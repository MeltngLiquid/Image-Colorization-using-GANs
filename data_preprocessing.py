# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S_x2gE3-5IwjEV7rPI32BV_9jgsvXclN
"""

import os
from skimage.io import imread
from skimage.color import rgb2gray
from skimage.transform import resize
from joblib import Parallel, delayed
import numpy as np

def load_and_preprocess_image(file_path, target_size):
    """
    Load an image, convert it to grayscale and RGB, and resize both.

    Parameters:
        file_path: Path to the image file.
        target_size: Target size for resizing (height, width).

    Returns:
        Tuple of (resized RGB image, resized grayscale image).
    """
    try:
        img = imread(file_path)  # Load the image
        if img.ndim == 2:  # Handle grayscale images
            img = np.stack([img] * 3, axis=-1)
        elif img.shape[-1] == 4:  # Handle alpha channel if present
            img = img[..., :3]
        img_resized = resize(img, target_size, anti_aliasing=True)  # Resize RGB
        img_gray = rgb2gray(img_resized)  # Convert to grayscale
        img_gray = img_gray[..., np.newaxis]  # Add channel dimension to grayscale
        return img_resized, img_gray
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None, None

def preprocess_images(folder, target_size=(256, 256), max_images=8000, n_jobs=-1):
    """
    Load and preprocess images from a folder structure into RGB and grayscale datasets.

    Parameters:
        folder: Root folder containing subfolders of images.
        target_size: Target size for resizing (height, width).
        max_images: Maximum number of images to process.
        n_jobs: Number of parallel jobs for processing.

    Returns:
        Tuple of (RGB images array, Grayscale images array).
    """
    # Recursively get list of all JPEG files from the folder structure
    files = []
    for root, _, filenames in os.walk(folder):
        for f in filenames:
            if f.lower().endswith('.jpeg'):
                files.append(os.path.join(root, f))

    print(f"Found {len(files)} JPEG images.")

    # Limit to the first `max_images`
    files = files[:max_images]

    if not files:
        raise ValueError(f"No JPEG images found in {folder}. Check the folder path and file extensions.")

    # Process images in parallel
    results = Parallel(n_jobs=n_jobs)(
        delayed(load_and_preprocess_image)(file, target_size) for file in files
    )

    # Separate RGB and grayscale images
    rgb_images = [r for r, g in results if r is not None]
    gray_images = [g for r, g in results if g is not None]

    print(f"Successfully processed {len(rgb_images)} images.")
    return np.array(rgb_images), np.array(gray_images)

def split_dataset(images_rgb, images_gray, test_size=0.2):
    """Split RGB and grayscale datasets into training and testing sets."""
    train_rgb, test_rgb, train_gray, test_gray = train_test_split(
        images_rgb, images_gray, test_size=test_size, random_state=42
    )
    return train_rgb, test_rgb, train_gray, test_gray

def create_tf_dataset(train_gray, train_rgb, batch_size=128, buffer_size=1000):
    """Create TensorFlow dataset for training."""
    dataset = tf.data.Dataset.from_tensor_slices((train_gray, train_rgb))
    dataset = dataset.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

folder_path = "/content/drive/MyDrive/imagenet-mini/train"  # Path to your images folder
target_size = (256, 256)        # Resize all images to this size
max_images = 8000           # Process only the first 2000 images
test_size = 0.2                 # 20% of the dataset for testing
batch_size = 128                 # Batch size for training

# Preprocess images
print("Preprocessing images...")
images_rgb, images_gray = preprocess_images(folder_path, target_size, max_images)
print(f"RGB images shape: {images_rgb.shape}")
print(f"Grayscale images shape: {images_gray.shape}")

# Split into train and test sets
train_rgb, test_rgb, train_gray, test_gray = split_dataset(images_rgb, images_gray, test_size)
print(f"Train RGB shape: {train_rgb.shape}, Train Gray shape: {train_gray.shape}")
print(f"Test RGB shape: {test_rgb.shape}, Test Gray shape: {test_gray.shape}")

# Create TensorFlow dataset
train_dataset = create_tf_dataset(train_gray, train_rgb, batch_size)
test_dataset = create_tf_dataset(test_gray, test_rgb, batch_size)
print("Training and testing datasets created.")

import matplotlib.pyplot as plt

# Function to display images
def display_images(images_rgb, images_gray, n_images=5):
    """
    Display `n_images` from both RGB and grayscale image datasets.
    """
    # Set up the figure with subplots
    fig, axes = plt.subplots(2, n_images, figsize=(15, 6))

    # Display RGB images
    for i in range(n_images):
        axes[0, i].imshow(images_rgb[i])
        axes[0, i].axis('off')  # Turn off axis
        axes[0, i].set_title(f"RGB Image {i+1}")

    # Display Grayscale images
    for i in range(n_images):
        axes[1, i].imshow(images_gray[i], cmap='gray')
        axes[1, i].axis('off')  # Turn off axis
        axes[1, i].set_title(f"Gray Image {i+1}")

    plt.tight_layout()
    plt.show()

# Display 5 images from RGB and grayscale datasets
print("Displaying sample images:")
display_images(images_rgb, images_gray, n_images=5)